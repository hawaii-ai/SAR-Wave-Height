{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'sarhs.generator' from '/home/psadow/lts/preserve/stopa/sar_hs/sar_hs/sarhs/generator.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import os, datetime\n",
    "import socket\n",
    "from IPython import get_ipython\n",
    "HOSTNAME = socket.gethostname()\n",
    "INTERACTIVE = get_ipython() is not None\n",
    "if INTERACTIVE:\n",
    "    get_ipython().run_line_magic('env', 'CUDA_VISIBLE_DEVICES=0')\n",
    "SHERPA_TRIAL_ID = os.environ.get('SHERPA_TRIAL_ID', '0000')\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' # Needed to avoid cudnn bug.\n",
    "\n",
    "import sherpa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/psadow/lts/preserve/stopa/sar_hs/sar_hs/')\n",
    "import sarhs.generator \n",
    "import importlib\n",
    "importlib.reload(sarhs.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    # Low-level features.\n",
    "    inputs = Input(shape=(72, 60, 2))\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    cnn = Model(inputs, x)\n",
    "\n",
    "    # High-level features.\n",
    "    inp = Input(shape=(32, ))  # 'hsSM', 'hsWW3v2', 'hsALT', 'altID', 'target' -> dropped\n",
    "    x = Dense(units=256, activation='relu')(inp)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    ann = Model(inputs=inp, outputs=x)\n",
    "    \n",
    "    # Combine\n",
    "    combinedInput = concatenate([cnn.output, ann.output])\n",
    "    x = Dense(256, activation=\"relu\")(combinedInput)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1, activation=\"softplus\")(x)\n",
    "    model = Model(inputs=[cnn.input, ann.input], outputs=x)\n",
    "    \n",
    "    opt = Adam(lr=0.00025897101528140915)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def step_decay_schedule(initial_lr=1e-3, decay_factor=0.40, step_size=4):\n",
    "    '''Wrapper function to create a LearningRateScheduler with step decay schedule.'''\n",
    "    def schedule(epoch):\n",
    "        if epoch >= 10 and epoch < 20:\n",
    "            exponent = 1\n",
    "        elif epoch >= 20 and epoch <= 118:\n",
    "            exponent = 2\n",
    "        else:\n",
    "            exponent = 3\n",
    "        return initial_lr * (decay_factor ** exponent)\n",
    "    return LearningRateScheduler(schedule)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3916/3916 [==============================] - 78s 20ms/step - loss: 0.6402 - val_loss: 0.3955 - lr: 1.6574e-05\n",
      "Epoch 2/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.3004 - val_loss: 0.2807 - lr: 1.6574e-05\n",
      "Epoch 3/60\n",
      "3916/3916 [==============================] - 80s 20ms/step - loss: 0.2488 - val_loss: 0.2133 - lr: 1.6574e-05\n",
      "Epoch 4/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.2186 - val_loss: 0.1931 - lr: 1.6574e-05\n",
      "Epoch 5/60\n",
      "3916/3916 [==============================] - 78s 20ms/step - loss: 0.1988 - val_loss: 0.1935 - lr: 1.6574e-05\n",
      "Epoch 6/60\n",
      "3916/3916 [==============================] - 78s 20ms/step - loss: 0.1853 - val_loss: 0.1771 - lr: 1.6574e-05\n",
      "Epoch 7/60\n",
      "3916/3916 [==============================] - 78s 20ms/step - loss: 0.1766 - val_loss: 0.2119 - lr: 1.6574e-05\n",
      "Epoch 8/60\n",
      "3916/3916 [==============================] - 78s 20ms/step - loss: 0.1677 - val_loss: 0.1690 - lr: 1.6574e-05\n",
      "Epoch 9/60\n",
      "3916/3916 [==============================] - 78s 20ms/step - loss: 0.1620 - val_loss: 0.1692 - lr: 1.6574e-05\n",
      "Epoch 10/60\n",
      "3916/3916 [==============================] - 78s 20ms/step - loss: 0.1559 - val_loss: 0.1683 - lr: 1.6574e-05\n",
      "Epoch 11/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.1806 - val_loss: 0.1804 - lr: 1.0359e-04\n",
      "Epoch 12/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.1593 - val_loss: 0.2019 - lr: 1.0359e-04\n",
      "Epoch 13/60\n",
      "3916/3916 [==============================] - 80s 20ms/step - loss: 0.1472 - val_loss: 0.1591 - lr: 1.0359e-04\n",
      "Epoch 14/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.1412 - val_loss: 0.1471 - lr: 1.0359e-04\n",
      "Epoch 15/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.1313 - val_loss: 0.1461 - lr: 1.0359e-04\n",
      "Epoch 16/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.1259 - val_loss: 0.1401 - lr: 1.0359e-04\n",
      "Epoch 17/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.1212 - val_loss: 0.1342 - lr: 1.0359e-04\n",
      "Epoch 18/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.1162 - val_loss: 0.1350 - lr: 1.0359e-04\n",
      "Epoch 19/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.1126 - val_loss: 0.1404 - lr: 1.0359e-04\n",
      "Epoch 20/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.1088 - val_loss: 0.1318 - lr: 1.0359e-04\n",
      "Epoch 21/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.0983 - val_loss: 0.1289 - lr: 4.1435e-05\n",
      "Epoch 22/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.0948 - val_loss: 0.1299 - lr: 4.1435e-05\n",
      "Epoch 23/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.0926 - val_loss: 0.1269 - lr: 4.1435e-05\n",
      "Epoch 24/60\n",
      "3916/3916 [==============================] - 78s 20ms/step - loss: 0.0906 - val_loss: 0.1300 - lr: 4.1435e-05\n",
      "Epoch 25/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.0889 - val_loss: 0.1267 - lr: 4.1435e-05\n",
      "Epoch 26/60\n",
      "3916/3916 [==============================] - 78s 20ms/step - loss: 0.0863 - val_loss: 0.1257 - lr: 4.1435e-05\n",
      "Epoch 27/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.0850 - val_loss: 0.1260 - lr: 4.1435e-05\n",
      "Epoch 28/60\n",
      "3916/3916 [==============================] - 78s 20ms/step - loss: 0.0835 - val_loss: 0.1426 - lr: 4.1435e-05\n",
      "Epoch 29/60\n",
      "3916/3916 [==============================] - 78s 20ms/step - loss: 0.0818 - val_loss: 0.1289 - lr: 4.1435e-05\n",
      "Epoch 30/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.0803 - val_loss: 0.1283 - lr: 4.1435e-05\n",
      "Epoch 31/60\n",
      "3916/3916 [==============================] - 79s 20ms/step - loss: 0.0790 - val_loss: 0.1279 - lr: 4.1435e-05\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model = define_model()\n",
    "file_model = 'model5.h5'\n",
    "#model.summary()\n",
    "#plot_model(model, to_file='model.png')\n",
    "\n",
    "# Dataset\n",
    "importlib.reload(sarhs.generator)\n",
    "batch_size = 128\n",
    "epochs = 60\n",
    "#filename = '/home/psadow/lts/preserve/stopa/sar_hs/data/alt/sar_hs.h5'\n",
    "filename = '/mnt/tmp/psadow/sar/sar_hs.h5'\n",
    "train = sarhs.generator.SARGenerator2(filename=filename, groups=['2015_2016', '2018'], batch_size=batch_size)\n",
    "valid = sarhs.generator.SARGenerator2(filename=filename, groups=['2017'], batch_size=batch_size)\n",
    "# test = sarhs.generator.SARGenerator2(filename=filename, split='2018', batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Callbacks\n",
    "reduce_lr = step_decay_schedule(initial_lr=0.00025897101528140915, decay_factor=0.40, step_size=4)\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=1) # This is slower than in paper.\n",
    "check = ModelCheckpoint(file_model, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "clbks = [reduce_lr, check, stop] #[reduce_lr, check, stop]\n",
    "\n",
    "# train = datagen(gen_data, 101171//batch_size, file, 'train', batch_size)\n",
    "# val = datagen(gen_data, 28906//batch_size, file, 'val', batch_size)\n",
    "history = model.fit(train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=valid,\n",
    "                    callbacks = clbks,\n",
    "                    verbose = 1 if INTERACTIVE else 2,\n",
    "                   )\n",
    "model.save(file_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
