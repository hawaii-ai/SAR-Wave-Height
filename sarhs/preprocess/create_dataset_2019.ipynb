{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'preprocess' from '/mnt/lts/nfs_fs02/sadow_lab/preserve/stopa/sar_hs/sar_hs/sarhs/preprocess/preprocess.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import preprocess\n",
    "import importlib\n",
    "importlib.reload(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S: float32\n",
      "cspcIm: float32\n",
      "cspcRe: float32\n",
      "incidenceAngle: float64\n",
      "latSAR: float32\n",
      "lonSAR: float32\n",
      "normalizedVariance: float32\n",
      "satellite: int64\n",
      "sigma0: float32\n",
      "timeSAR: float64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'year' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-545dbddc0f63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Find examples from this sat, year, month.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/libs/anaconda3/envs/t2/lib/python3.8/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'year' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "# Create new h5 file with following:\n",
    "# 1) Data separated by sat year month. No need to combine because this is for prediction.\n",
    "# 2) Features scaled.\n",
    "#groups = {'2015_2016':[2015, 2016], '2017':[2017], '2018':[2018]}\n",
    "#groups = {'2019':[2019]}\n",
    "groups = {}\n",
    "for isat in range(2):\n",
    "    for year in [2019]:\n",
    "        for imonth in range(12):\n",
    "            sat = 'A' if isat==1 else 'B'\n",
    "            month = imonth+1\n",
    "            name = f'S1{sat}_{year}{month:02d}S'\n",
    "            groups[name] = (isat, year, month)\n",
    "\n",
    "file_src = '/home/psadow/lts/preserve/stopa/sar_hs/data/alt/aggregated_2019.h5'\n",
    "file_dest = '/home/psadow/lts/preserve/stopa/sar_hs/data/alt/sar_hs_2019.h5'\n",
    "\n",
    "# Print fields of source file.\n",
    "with h5py.File(file_src, 'r') as f:\n",
    "    for k in [k for k in f.keys()]:\n",
    "        print(f'{k}: {f[k].dtype}')\n",
    "\n",
    "# Create h5.\n",
    "with h5py.File(file_src, 'r') as fs, h5py.File(file_dest, 'w') as fd:\n",
    "    for group_name, (sat, year, month) in groups.items():\n",
    "        grp = fd.create_group(group_name)\n",
    "        \n",
    "        # Find examples from this sat, year, month.\n",
    "        indices = np.ones_like(fs['year'][:], dtype='bool')\n",
    "        indices = np.logical_and(fs['year'][:] == year, indices)\n",
    "        indices = np.logical_and(fs['month'][:] == month, indices)\n",
    "        indices = np.logical_and(fs['satellite'][:] == sat, indices)\n",
    "        num_examples = indices.sum()\n",
    "        print(f'Found {num_examples} events for sat {sat}, year {year}, month {month}.')\n",
    "        \n",
    "        # Write data from this year.\n",
    "        grp.create_dataset('year', data=fs['year'][indices])    \n",
    "        \n",
    "        # Get 22 CWAVE features. \n",
    "        cwave = np.hstack([fs['S'][indices,...], fs['sigma0'][indices].reshape(-1,1), fs['normalizedVariance'][indices].reshape(-1,1)])\n",
    "        cwave = preprocess.conv_cwave(cwave) # Remove extrema, then standardize with hardcoded mean,vars.\n",
    "        grp.create_dataset('cwave', data=cwave)\n",
    "        \n",
    "        # Additional features. \n",
    "        #dx = preprocess.conv_dx(fs['dx'][indices])\n",
    "        #dt = preprocess.conv_dt(fs['dt'][indices])\n",
    "        #grp.create_dataset('dxdt', data=np.column_stack([dx, dt]))\n",
    "        \n",
    "        latSAR = fs['latSAR'][indices]\n",
    "        lonSAR = fs['lonSAR'][indices]\n",
    "        latSARcossin = preprocess.conv_position(latSAR) # Gets cos and sin\n",
    "        lonSARcossin = preprocess.conv_position(lonSAR)\n",
    "        grp.create_dataset('latlonSAR', data=np.column_stack([latSAR, lonSAR]))\n",
    "        grp.create_dataset('latlonSARcossin', data=np.hstack([latSARcossin, lonSARcossin]))\n",
    "        \n",
    "        timeSAR = fs['timeSAR'][indices]\n",
    "        todSAR = preprocess.conv_time(timeSAR)\n",
    "        grp.create_dataset('timeSAR', data=timeSAR, shape=(timeSAR.shape[0], 1))\n",
    "        grp.create_dataset('todSAR', data=todSAR, shape=(todSAR.shape[0], 1))\n",
    "        \n",
    "        incidence = preprocess.conv_incidence(fs['incidenceAngle'][indices]) # Separates into 2 var.\n",
    "        grp.create_dataset('incidence', data=incidence)\n",
    "        \n",
    "        satellite = fs['satellite'][indices]\n",
    "        grp.create_dataset('satellite', data=satellite, shape=(satellite.shape[0], 1))\n",
    "        \n",
    "        # Altimeter\n",
    "        #hsALT = fs['hsALT'][indices]\n",
    "        #grp.create_dataset('hsALT', data=hsALT, shape=(hsALT.shape[0], 1))\n",
    "        \n",
    "        # Get spectral data.\n",
    "        re = preprocess.conv_real(fs['cspcRe'][indices,...])\n",
    "        im = preprocess.conv_imaginary(fs['cspcIm'][indices,...])\n",
    "        x = np.stack((re, im), axis=3)\n",
    "        grp.create_dataset('spectrum', data=x)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
