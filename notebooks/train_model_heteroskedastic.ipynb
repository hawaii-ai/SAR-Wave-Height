{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train neural network to predict significant wave height from SAR spectra.\n",
    "# Train with heteroskedastic regression uncertainty estimates.\n",
    "# Author: Peter Sadowski, Dec 2020\n",
    "import os, sys\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' # Needed to avoid cudnn bug.\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence, plot_model\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "sys.path = ['../'] + sys.path\n",
    "from sarhs.generator import SARGenerator\n",
    "from sarhs.heteroskedastic import Gaussian_NLL, Gaussian_MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    # Low-level features.\n",
    "    inputs = Input(shape=(72, 60, 2))\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    cnn = Model(inputs, x)\n",
    "\n",
    "    # High-level features.\n",
    "    inp = Input(shape=(32, ))  # 'hsSM', 'hsWW3v2', 'hsALT', 'altID', 'target' -> dropped\n",
    "    x = Dense(units=256, activation='relu')(inp)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    ann = Model(inputs=inp, outputs=x)\n",
    "    \n",
    "    # Combine\n",
    "    combinedInput = concatenate([cnn.output, ann.output])\n",
    "    x = Dense(256, activation=\"relu\")(combinedInput)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation=\"relu\", name='penultimate')(x)  \n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(2, activation=\"softplus\", name='output')(x)\n",
    "    model = Model(inputs=[cnn.input, ann.input], outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/123\n",
      "4542/4542 [==============================] - 158s 35ms/step - loss: 0.5852 - Gaussian_MSE: 0.3387 - val_loss: 0.5320 - val_Gaussian_MSE: 0.1879 - lr: 1.0000e-04\n",
      "Epoch 2/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: 0.2333 - Gaussian_MSE: 0.1823 - val_loss: 0.5574 - val_Gaussian_MSE: 0.2450 - lr: 1.0000e-04\n",
      "Epoch 3/123\n",
      "4542/4542 [==============================] - 116s 26ms/step - loss: 0.1139 - Gaussian_MSE: 0.1571 - val_loss: 0.4102 - val_Gaussian_MSE: 0.1516 - lr: 9.0000e-05\n",
      "Epoch 4/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: 0.0434 - Gaussian_MSE: 0.1438 - val_loss: 0.2912 - val_Gaussian_MSE: 0.1284 - lr: 9.0000e-05\n",
      "Epoch 5/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.0086 - Gaussian_MSE: 0.1360 - val_loss: 0.2653 - val_Gaussian_MSE: 0.1267 - lr: 9.0000e-05\n",
      "Epoch 6/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: -0.0602 - Gaussian_MSE: 0.1281 - val_loss: 0.2567 - val_Gaussian_MSE: 0.1225 - lr: 9.0000e-05\n",
      "Epoch 7/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.1110 - Gaussian_MSE: 0.1223 - val_loss: 0.2541 - val_Gaussian_MSE: 0.1233 - lr: 9.0000e-05\n",
      "Epoch 8/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.1539 - Gaussian_MSE: 0.1176 - val_loss: 0.2421 - val_Gaussian_MSE: 0.1316 - lr: 9.0000e-05\n",
      "Epoch 9/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.1944 - Gaussian_MSE: 0.1145 - val_loss: 0.2025 - val_Gaussian_MSE: 0.1166 - lr: 9.0000e-05\n",
      "Epoch 10/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.2393 - Gaussian_MSE: 0.1104 - val_loss: 0.2000 - val_Gaussian_MSE: 0.1162 - lr: 9.0000e-05\n",
      "Epoch 11/123\n",
      "4542/4542 [==============================] - 119s 26ms/step - loss: -0.2841 - Gaussian_MSE: 0.1061 - val_loss: 0.1844 - val_Gaussian_MSE: 0.1173 - lr: 9.0000e-05\n",
      "Epoch 12/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: -0.3228 - Gaussian_MSE: 0.1042 - val_loss: 0.1674 - val_Gaussian_MSE: 0.1097 - lr: 9.0000e-05\n",
      "Epoch 13/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.3624 - Gaussian_MSE: 0.1012 - val_loss: 0.1978 - val_Gaussian_MSE: 0.1187 - lr: 9.0000e-05\n",
      "Epoch 14/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.3968 - Gaussian_MSE: 0.0974 - val_loss: 0.3131 - val_Gaussian_MSE: 0.1213 - lr: 8.1000e-05\n",
      "Epoch 15/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.4343 - Gaussian_MSE: 0.0940 - val_loss: 0.1546 - val_Gaussian_MSE: 0.1101 - lr: 7.2900e-05\n",
      "Epoch 16/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.4599 - Gaussian_MSE: 0.0914 - val_loss: 0.1658 - val_Gaussian_MSE: 0.1114 - lr: 7.2900e-05\n",
      "Epoch 17/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: -0.4936 - Gaussian_MSE: 0.0889 - val_loss: 0.1477 - val_Gaussian_MSE: 0.1089 - lr: 6.5610e-05\n",
      "Epoch 18/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: -0.5162 - Gaussian_MSE: 0.0873 - val_loss: 0.1519 - val_Gaussian_MSE: 0.1096 - lr: 6.5610e-05\n",
      "Epoch 19/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: -0.5374 - Gaussian_MSE: 0.0855 - val_loss: 0.1969 - val_Gaussian_MSE: 0.1158 - lr: 5.9049e-05\n",
      "Epoch 20/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.5601 - Gaussian_MSE: 0.0827 - val_loss: 0.2537 - val_Gaussian_MSE: 0.1365 - lr: 5.3144e-05\n",
      "Epoch 21/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.5770 - Gaussian_MSE: 0.0806 - val_loss: 0.1516 - val_Gaussian_MSE: 0.1084 - lr: 4.7830e-05\n",
      "Epoch 22/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.5945 - Gaussian_MSE: 0.0790 - val_loss: 0.1640 - val_Gaussian_MSE: 0.1136 - lr: 4.3047e-05\n",
      "Epoch 23/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.6089 - Gaussian_MSE: 0.0777 - val_loss: 0.1653 - val_Gaussian_MSE: 0.1115 - lr: 3.8742e-05\n",
      "Epoch 24/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.6220 - Gaussian_MSE: 0.0761 - val_loss: 0.1758 - val_Gaussian_MSE: 0.1098 - lr: 3.4868e-05\n",
      "Epoch 25/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.6338 - Gaussian_MSE: 0.0745 - val_loss: 0.1700 - val_Gaussian_MSE: 0.1107 - lr: 3.1381e-05\n",
      "Epoch 26/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: -0.6429 - Gaussian_MSE: 0.0738 - val_loss: 0.1887 - val_Gaussian_MSE: 0.1139 - lr: 2.8243e-05\n",
      "Epoch 27/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.6517 - Gaussian_MSE: 0.0725 - val_loss: 0.1845 - val_Gaussian_MSE: 0.1114 - lr: 2.5419e-05\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "file_model = '../models/heteroskedastic_2017.h5'\n",
    "model = define_model()\n",
    "model.compile(loss=Gaussian_NLL, optimizer=Adam(lr=0.0001), metrics=[Gaussian_MSE])\n",
    "\n",
    "# Dataset\n",
    "batch_size = 128\n",
    "epochs = 123\n",
    "filename = '/mnt/tmp/psadow/sar/sar_hs.h5'\n",
    "#filename = '../../data/alt/sar_hs.h5'\n",
    "train = SARGenerator(filename=filename, \n",
    "                     subgroups=['2015_2016', '2017'], \n",
    "                     batch_size=batch_size)\n",
    "valid = SARGenerator(filename=filename, subgroups=['2018'], batch_size=batch_size)\n",
    "\n",
    "# Callbacks\n",
    "# This LR schedule is slower than in the paper.\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=1) \n",
    "check = ModelCheckpoint(file_model, monitor='val_loss', verbose=0,\n",
    "                        save_best_only=True, save_weights_only=False,\n",
    "                        mode='auto', save_freq='epoch')\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, \n",
    "                     mode='auto', baseline=None, restore_best_weights=False)\n",
    "clbks = [reduce_lr, check, stop]\n",
    "\n",
    "history = model.fit(train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=valid,\n",
    "                    callbacks=clbks,\n",
    "                    verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:t2] *",
   "language": "python",
   "name": "conda-env-t2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
