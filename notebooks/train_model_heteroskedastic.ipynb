{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train neural network to predict significant wave height from SAR spectra.\n",
    "# Train with heteroskedastic regression uncertainty estimates.\n",
    "# Author: Peter Sadowski, Dec 2020\n",
    "import os, sys\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' # Needed to avoid cudnn bug.\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence, plot_model\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "sys.path = ['../'] + sys.path\n",
    "from sarhs.generator import SARGenerator\n",
    "from sarhs.heteroskedastic import Gaussian_NLL, Gaussian_MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    # Low-level features.\n",
    "    inputs = Input(shape=(72, 60, 2))\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    cnn = Model(inputs, x)\n",
    "\n",
    "    # High-level features.\n",
    "    inp = Input(shape=(32, ))  # 'hsSM', 'hsWW3v2', 'hsALT', 'altID', 'target' -> dropped\n",
    "    x = Dense(units=256, activation='relu')(inp)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    ann = Model(inputs=inp, outputs=x)\n",
    "    \n",
    "    # Combine\n",
    "    combinedInput = concatenate([cnn.output, ann.output])\n",
    "    x = Dense(256, activation=\"relu\")(combinedInput)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation=\"relu\", name='penultimate')(x)  \n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(2, activation=\"softplus\", name='output')(x)\n",
    "    model = Model(inputs=[cnn.input, ann.input], outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/123\n",
      "4449/4449 [==============================] - 108s 24ms/step - loss: 0.6521 - Gaussian_MSE: 0.3641 - val_loss: 0.4954 - val_Gaussian_MSE: 0.1896 - lr: 1.0000e-04\n",
      "Epoch 2/123\n",
      "4449/4449 [==============================] - 87s 20ms/step - loss: 0.2711 - Gaussian_MSE: 0.1766 - val_loss: 0.3721 - val_Gaussian_MSE: 0.1433 - lr: 1.0000e-04\n",
      "Epoch 3/123\n",
      "4449/4449 [==============================] - 88s 20ms/step - loss: 0.1545 - Gaussian_MSE: 0.1507 - val_loss: 0.3046 - val_Gaussian_MSE: 0.1316 - lr: 1.0000e-04\n",
      "Epoch 4/123\n",
      "4449/4449 [==============================] - 88s 20ms/step - loss: 0.0874 - Gaussian_MSE: 0.1377 - val_loss: 0.3066 - val_Gaussian_MSE: 0.1312 - lr: 1.0000e-04\n",
      "Epoch 5/123\n",
      "4449/4449 [==============================] - 88s 20ms/step - loss: 0.0320 - Gaussian_MSE: 0.1295 - val_loss: 0.2606 - val_Gaussian_MSE: 0.1278 - lr: 9.0000e-05\n",
      "Epoch 6/123\n",
      "4449/4449 [==============================] - 88s 20ms/step - loss: -0.0157 - Gaussian_MSE: 0.1221 - val_loss: 0.2725 - val_Gaussian_MSE: 0.1263 - lr: 9.0000e-05\n",
      "Epoch 7/123\n",
      "4449/4449 [==============================] - 88s 20ms/step - loss: -0.0632 - Gaussian_MSE: 0.1149 - val_loss: 0.2139 - val_Gaussian_MSE: 0.1159 - lr: 8.1000e-05\n",
      "Epoch 8/123\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: -0.1039 - Gaussian_MSE: 0.1112 - val_loss: 0.1800 - val_Gaussian_MSE: 0.1129 - lr: 8.1000e-05\n",
      "Epoch 9/123\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: -0.1412 - Gaussian_MSE: 0.1069 - val_loss: 0.2412 - val_Gaussian_MSE: 0.1140 - lr: 8.1000e-05\n",
      "Epoch 10/123\n",
      "4449/4449 [==============================] - 88s 20ms/step - loss: -0.1835 - Gaussian_MSE: 0.1028 - val_loss: 0.1639 - val_Gaussian_MSE: 0.1092 - lr: 7.2900e-05\n",
      "Epoch 11/123\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: -0.2194 - Gaussian_MSE: 0.0995 - val_loss: 0.1671 - val_Gaussian_MSE: 0.1090 - lr: 7.2900e-05\n",
      "Epoch 12/123\n",
      "4449/4449 [==============================] - 88s 20ms/step - loss: -0.2580 - Gaussian_MSE: 0.0958 - val_loss: 0.1833 - val_Gaussian_MSE: 0.1162 - lr: 6.5610e-05\n",
      "Epoch 13/123\n",
      "4449/4449 [==============================] - 88s 20ms/step - loss: -0.2895 - Gaussian_MSE: 0.0931 - val_loss: 0.8057 - val_Gaussian_MSE: 0.3449 - lr: 5.9049e-05\n",
      "Epoch 14/123\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: -0.3191 - Gaussian_MSE: 0.0902 - val_loss: 0.1561 - val_Gaussian_MSE: 0.1079 - lr: 5.3144e-05\n",
      "Epoch 15/123\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: -0.3413 - Gaussian_MSE: 0.0877 - val_loss: 0.1613 - val_Gaussian_MSE: 0.1072 - lr: 5.3144e-05\n",
      "Epoch 16/123\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: -0.3719 - Gaussian_MSE: 0.0855 - val_loss: 0.1496 - val_Gaussian_MSE: 0.1080 - lr: 4.7830e-05\n",
      "Epoch 17/123\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: -0.3938 - Gaussian_MSE: 0.0835 - val_loss: 0.1539 - val_Gaussian_MSE: 0.1081 - lr: 4.7830e-05\n",
      "Epoch 18/123\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: -0.4179 - Gaussian_MSE: 0.0821 - val_loss: 0.1617 - val_Gaussian_MSE: 0.1090 - lr: 4.3047e-05\n",
      "Epoch 19/123\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: -0.4402 - Gaussian_MSE: 0.0801 - val_loss: 0.1467 - val_Gaussian_MSE: 0.1079 - lr: 3.8742e-05\n",
      "Epoch 20/123\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: -0.4597 - Gaussian_MSE: 0.0792 - val_loss: 0.1534 - val_Gaussian_MSE: 0.1070 - lr: 3.8742e-05\n",
      "Epoch 21/123\n",
      "4449/4449 [==============================] - 88s 20ms/step - loss: -0.4812 - Gaussian_MSE: 0.0770 - val_loss: 0.1737 - val_Gaussian_MSE: 0.1119 - lr: 3.4868e-05\n",
      "Epoch 22/123\n",
      "4449/4449 [==============================] - 88s 20ms/step - loss: -0.5023 - Gaussian_MSE: 0.0755 - val_loss: 0.1536 - val_Gaussian_MSE: 0.1061 - lr: 3.1381e-05\n",
      "Epoch 23/123\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: -0.5209 - Gaussian_MSE: 0.0739 - val_loss: 0.1586 - val_Gaussian_MSE: 0.1063 - lr: 2.8243e-05\n",
      "Epoch 24/123\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: -0.5365 - Gaussian_MSE: 0.0730 - val_loss: 0.1832 - val_Gaussian_MSE: 0.1093 - lr: 2.5419e-05\n",
      "Epoch 25/123\n",
      "4449/4449 [==============================] - 88s 20ms/step - loss: -0.5521 - Gaussian_MSE: 0.0711 - val_loss: 0.1797 - val_Gaussian_MSE: 0.1068 - lr: 2.2877e-05\n",
      "Epoch 26/123\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: -0.5654 - Gaussian_MSE: 0.0704 - val_loss: 0.2050 - val_Gaussian_MSE: 0.1071 - lr: 2.0589e-05\n",
      "Epoch 27/123\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: -0.5789 - Gaussian_MSE: 0.0688 - val_loss: 0.2015 - val_Gaussian_MSE: 0.1082 - lr: 1.8530e-05\n",
      "Epoch 28/123\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: -0.5934 - Gaussian_MSE: 0.0677 - val_loss: 0.2270 - val_Gaussian_MSE: 0.1080 - lr: 1.6677e-05\n",
      "Epoch 29/123\n",
      "4449/4449 [==============================] - 88s 20ms/step - loss: -0.6007 - Gaussian_MSE: 0.0672 - val_loss: 0.1995 - val_Gaussian_MSE: 0.1105 - lr: 1.5009e-05\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "file_model = '../models/heteroskedastic_2017.h5'\n",
    "model = define_model()\n",
    "model.compile(loss=Gaussian_NLL, optimizer=Adam(lr=0.0001), metrics=[Gaussian_MSE])\n",
    "\n",
    "# Dataset\n",
    "batch_size = 128\n",
    "epochs = 123\n",
    "#filename = '../../data/alt/sar_hs.h5'\n",
    "filename = '/mnt/tmp/psadow/sar/sar_hs.h5'\n",
    "train = SARGenerator(filename=filename, \n",
    "                     subgroups=['2015_2016', '2017'], \n",
    "                     batch_size=batch_size)\n",
    "valid = SARGenerator(filename=filename, subgroups=['2018'], batch_size=batch_size)\n",
    "# filename = '/mnt/tmp/psadow/sar/sar_hs.h5'\n",
    "# epochs = 25\n",
    "# train = SARGenerator(filename=filename, \n",
    "#                      subgroups=['2015_2016', '2017', '2018'], # Train on all data without early stopping.\n",
    "#                      batch_size=batch_size)\n",
    "\n",
    "# Callbacks\n",
    "# This LR schedule is slower than in the paper.\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=1) \n",
    "check = ModelCheckpoint(file_model, monitor='val_loss', verbose=0,\n",
    "                        save_best_only=True, save_weights_only=False,\n",
    "                        mode='auto', save_freq='epoch')\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, \n",
    "                     mode='auto', baseline=None, restore_best_weights=False)\n",
    "clbks = [reduce_lr, check, stop]\n",
    "\n",
    "history = model.fit(train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=valid,\n",
    "                    callbacks=clbks,\n",
    "                    verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
