{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train neural network to predict significant wave height from SAR spectra.\n",
    "# Train with heteroskedastic regression uncertainty estimates.\n",
    "# Author: Peter Sadowski, Dec 2020\n",
    "import os, sys\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' # Needed to avoid cudnn bug.\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence, plot_model\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "sys.path = ['../'] + sys.path\n",
    "from sarhs.generator import SARGenerator\n",
    "from sarhs.heteroskedastic import Gaussian_NLL, Gaussian_MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    # Low-level features.\n",
    "    inputs = Input(shape=(72, 60, 2))\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    cnn = Model(inputs, x)\n",
    "\n",
    "    # High-level features.\n",
    "    inp = Input(shape=(32, ))  # 'hsSM', 'hsWW3v2', 'hsALT', 'altID', 'target' -> dropped\n",
    "    x = Dense(units=256, activation='relu')(inp)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    ann = Model(inputs=inp, outputs=x)\n",
    "    \n",
    "    # Combine\n",
    "    combinedInput = concatenate([cnn.output, ann.output])\n",
    "    x = Dense(256, activation=\"relu\")(combinedInput)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation=\"relu\", name='penultimate')(x)  \n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(2, activation=\"softplus\", name='output')(x)\n",
    "    model = Model(inputs=[cnn.input, ann.input], outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/123\n",
      "4542/4542 [==============================] - 158s 35ms/step - loss: 0.5852 - Gaussian_MSE: 0.3387 - val_loss: 0.5320 - val_Gaussian_MSE: 0.1879 - lr: 1.0000e-04\n",
      "Epoch 2/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: 0.2333 - Gaussian_MSE: 0.1823 - val_loss: 0.5574 - val_Gaussian_MSE: 0.2450 - lr: 1.0000e-04\n",
      "Epoch 3/123\n",
      "4542/4542 [==============================] - 116s 26ms/step - loss: 0.1139 - Gaussian_MSE: 0.1571 - val_loss: 0.4102 - val_Gaussian_MSE: 0.1516 - lr: 9.0000e-05\n",
      "Epoch 4/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: 0.0434 - Gaussian_MSE: 0.1438 - val_loss: 0.2912 - val_Gaussian_MSE: 0.1284 - lr: 9.0000e-05\n",
      "Epoch 5/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.0086 - Gaussian_MSE: 0.1360 - val_loss: 0.2653 - val_Gaussian_MSE: 0.1267 - lr: 9.0000e-05\n",
      "Epoch 6/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: -0.0602 - Gaussian_MSE: 0.1281 - val_loss: 0.2567 - val_Gaussian_MSE: 0.1225 - lr: 9.0000e-05\n",
      "Epoch 7/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.1110 - Gaussian_MSE: 0.1223 - val_loss: 0.2541 - val_Gaussian_MSE: 0.1233 - lr: 9.0000e-05\n",
      "Epoch 8/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.1539 - Gaussian_MSE: 0.1176 - val_loss: 0.2421 - val_Gaussian_MSE: 0.1316 - lr: 9.0000e-05\n",
      "Epoch 9/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.1944 - Gaussian_MSE: 0.1145 - val_loss: 0.2025 - val_Gaussian_MSE: 0.1166 - lr: 9.0000e-05\n",
      "Epoch 10/123\n",
      "4542/4542 [==============================] - 117s 26ms/step - loss: -0.2393 - Gaussian_MSE: 0.1104 - val_loss: 0.2000 - val_Gaussian_MSE: 0.1162 - lr: 9.0000e-05\n",
      "Epoch 11/123\n",
      "4542/4542 [==============================] - 119s 26ms/step - loss: -0.2841 - Gaussian_MSE: 0.1061 - val_loss: 0.1844 - val_Gaussian_MSE: 0.1173 - lr: 9.0000e-05\n",
      "Epoch 12/123\n",
      "1399/4542 [========>.....................] - ETA: 1:11 - loss: -0.3384 - Gaussian_MSE: 0.1018"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "file_model = 'model.h5'\n",
    "model = define_model()\n",
    "model.compile(loss=Gaussian_NLL, optimizer=Adam(lr=0.0001), metrics=[Gaussian_MSE])\n",
    "\n",
    "# Dataset\n",
    "batch_size = 128\n",
    "epochs = 123\n",
    "filename = '/mnt/tmp/psadow/sar/sar_hs.h5'\n",
    "#filename = '../../data/alt/sar_hs.h5'\n",
    "train = SARGenerator(filename=filename, \n",
    "                     subgroups=['2015_2016', '2017'], \n",
    "                     batch_size=batch_size)\n",
    "valid = SARGenerator(filename=filename, subgroups=['2018'], batch_size=batch_size)\n",
    "\n",
    "# Callbacks\n",
    "# This LR schedule is slower than in the paper.\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=1) \n",
    "check = ModelCheckpoint(file_model, monitor='val_loss', verbose=0,\n",
    "                        save_best_only=True, save_weights_only=False,\n",
    "                        mode='auto', save_freq='epoch')\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, \n",
    "                     mode='auto', baseline=None, restore_best_weights=False)\n",
    "clbks = [reduce_lr, check, stop]\n",
    "\n",
    "history = model.fit(train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=valid,\n",
    "                    callbacks=clbks,\n",
    "                    verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:t2] *",
   "language": "python",
   "name": "conda-env-t2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
