{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train neural network to predict significant wave height from SAR spectra.\n",
    "# Author: Peter Sadowski, Dec 2020\n",
    "import os, sys\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' # Needed to avoid cudnn bug.\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence, plot_model\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "sys.path = ['../'] + sys.path\n",
    "from sarhs.generator import SARGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    # Low-level features.\n",
    "    inputs = Input(shape=(72, 60, 2))\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    cnn = Model(inputs, x)\n",
    "\n",
    "    # High-level features.\n",
    "    inp = Input(shape=(32, ))  # 'hsSM', 'hsWW3v2', 'hsALT', 'altID', 'target' -> dropped\n",
    "    x = Dense(units=256, activation='relu')(inp)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    ann = Model(inputs=inp, outputs=x)\n",
    "    \n",
    "    # Combine\n",
    "    combinedInput = concatenate([cnn.output, ann.output])\n",
    "    x = Dense(256, activation=\"relu\")(combinedInput)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1, activation=\"softplus\")(x)\n",
    "    model = Model(inputs=[cnn.input, ann.input], outputs=x)\n",
    "    \n",
    "    opt = Adam(lr=0.00025897101528140915)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/123\n",
      "4542/4542 [==============================] - 158s 35ms/step - loss: 0.2654 - val_loss: 0.1744 - lr: 2.5897e-04\n",
      "Epoch 2/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.1598 - val_loss: 0.1452 - lr: 2.5897e-04\n",
      "Epoch 3/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.1397 - val_loss: 0.1460 - lr: 2.5897e-04\n",
      "Epoch 4/123\n",
      "4542/4542 [==============================] - 119s 26ms/step - loss: 0.1252 - val_loss: 0.1377 - lr: 2.3307e-04\n",
      "Epoch 5/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.1167 - val_loss: 0.1272 - lr: 2.3307e-04\n",
      "Epoch 6/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.1100 - val_loss: 0.1244 - lr: 2.3307e-04\n",
      "Epoch 7/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.1038 - val_loss: 0.1296 - lr: 2.3307e-04\n",
      "Epoch 8/123\n",
      "4542/4542 [==============================] - 119s 26ms/step - loss: 0.0975 - val_loss: 0.1190 - lr: 2.0977e-04\n",
      "Epoch 9/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.0922 - val_loss: 0.1164 - lr: 2.0977e-04\n",
      "Epoch 10/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.0903 - val_loss: 0.1205 - lr: 2.0977e-04\n",
      "Epoch 11/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.0856 - val_loss: 0.1323 - lr: 1.8879e-04\n",
      "Epoch 12/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.0817 - val_loss: 0.1228 - lr: 1.6991e-04\n",
      "Epoch 13/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.0784 - val_loss: 0.1192 - lr: 1.5292e-04\n",
      "Epoch 14/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.0767 - val_loss: 0.1158 - lr: 1.3763e-04\n",
      "Epoch 15/123\n",
      "4542/4542 [==============================] - 119s 26ms/step - loss: 0.0739 - val_loss: 0.1142 - lr: 1.3763e-04\n",
      "Epoch 16/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.0727 - val_loss: 0.1239 - lr: 1.3763e-04\n",
      "Epoch 17/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.0711 - val_loss: 0.1184 - lr: 1.2387e-04\n",
      "Epoch 18/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.0684 - val_loss: 0.1232 - lr: 1.1148e-04\n",
      "Epoch 19/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.0670 - val_loss: 0.1209 - lr: 1.0033e-04\n",
      "Epoch 20/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.0650 - val_loss: 0.1154 - lr: 9.0298e-05\n",
      "Epoch 21/123\n",
      "4542/4542 [==============================] - 119s 26ms/step - loss: 0.0630 - val_loss: 0.1189 - lr: 8.1268e-05\n",
      "Epoch 22/123\n",
      "4542/4542 [==============================] - 118s 26ms/step - loss: 0.0618 - val_loss: 0.1308 - lr: 7.3141e-05\n",
      "Epoch 23/123\n",
      "4542/4542 [==============================] - 119s 26ms/step - loss: 0.0604 - val_loss: 0.1161 - lr: 6.5827e-05\n",
      "Epoch 24/123\n",
      "2729/4542 [=================>............] - ETA: 40s - loss: 0.0581"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model = define_model()\n",
    "file_model = 'model.h5'\n",
    "#model.summary()\n",
    "#plot_model(model, to_file='model.png')\n",
    "\n",
    "# Dataset\n",
    "batch_size = 128\n",
    "epochs = 123\n",
    "filename = '/mnt/tmp/psadow/sar/sar_hs.h5'\n",
    "#filename = '../../data/alt/sar_hs.h5'\n",
    "train = SARGenerator(filename=filename, \n",
    "                     groups=['2015_2016', '2017'], \n",
    "                     batch_size=batch_size)\n",
    "valid = SARGenerator(filename=filename, groups=['2018'], batch_size=batch_size)\n",
    "\n",
    "# Callbacks\n",
    "# This LR schedule is slower than in the paper.\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=1) \n",
    "check = ModelCheckpoint(file_model, monitor='val_loss', verbose=0,\n",
    "                        save_best_only=True, save_weights_only=False,\n",
    "                        mode='auto', save_freq='epoch')\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, \n",
    "                     mode='auto', baseline=None, restore_best_weights=False)\n",
    "clbks = [reduce_lr, check, stop]\n",
    "\n",
    "history = model.fit(train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=valid,\n",
    "                    callbacks=clbks,\n",
    "                    verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
