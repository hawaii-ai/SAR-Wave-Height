{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads NetCDF4 files and combines them into hdf5 file.\n",
    "# Author: Peter Sadowski, Dec 2020\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import glob\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 65 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/psadow/libs/anaconda3/envs/01_16_2021/lib/python3.8/site-packages/numpy/core/_asarray.py:83: UserWarning: WARNING: valid_min not used since it\n",
      "cannot be safely cast to variable data type\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/home/psadow/libs/anaconda3/envs/01_16_2021/lib/python3.8/site-packages/numpy/core/_asarray.py:83: UserWarning: WARNING: valid_max not used since it\n",
      "cannot be safely cast to variable data type\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "65it [08:42,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregate netCDF4 files into large h5 file.\n",
    "#files_src = glob.glob(\"/mnt/lts/nfs_fs02/sadow_lab/personal/quachb/sar_hs/*.nc\")\n",
    "#files_src = [f for f in files_src if 'ALT' in f]\n",
    "#files_src = sorted(glob.glob(\"/mnt/lts/nfs_fs02/sadow_lab/preserve/stopa/sar_hs/data/S1_2019/*.nc\"))\n",
    "#files_src = sorted(glob.glob(\"/mnt/lts/nfs_fs02/sadow_lab/preserve/stopa/sar_hs/data/S1_tropicalCyclones/*.nc\"))\n",
    "files_src = sorted(glob.glob(\"/mnt/lts/nfs_fs02/sadow_lab/preserve/stopa/sar_hs/data/2021/*.nc\"))\n",
    "print(f'Found {len(files_src)} files.')\n",
    "\n",
    "#file_dest =  \"/mnt/lts/nfs_fs02/sadow_lab/preserve/stopa/sar_hs/data/alt/aggregated_ALT.h5\"\n",
    "#file_dest =  \"/mnt/tmp/psadow/sar/aggregated_ALT.h5\"\n",
    "#file_dest = \"/mnt/tmp/psadow/sar/aggregated_2019.h5\"\n",
    "#file_dest =  \"/mnt/lts/nfs_fs02/sadow_lab/preserve/stopa/sar_hs/data/alt/aggregated_2019.h5\"\n",
    "file_dest =  \"/mnt/lts/nfs_fs02/sadow_lab/preserve/stopa/sar_hs/data/alt/aggregated.h5\"\n",
    "\n",
    "\n",
    "#keys = ['timeSAR', 'timeALT', 'lonSAR', 'lonALT', 'latSAR', 'latALT', 'hsALT', 'dx', 'dt', 'nk', 'hsSM', 'incidenceAngle', 'sigma0', 'normalizedVariance', 'S']\n",
    "#keys = ['timeSAR', 'lonSAR',  'latSAR', 'incidenceAngle', 'sigma0', 'normalizedVariance', 'S']\n",
    "#keys += ['cspcRe', 'cspcIm']\n",
    "#keys = ['timeSAR', 'lonSAR',  'latSAR', 'incidenceAngle', 'sigma0', 'normalizedVariance', 'py_S', 'cspcRe', 'cspcIm'] #'py_cspcRe', 'py_cspcIm']\n",
    "keys = ['timeSAR', 'timeALT', 'lonSAR', 'lonALT', 'latSAR', 'latALT', 'hsALT', 'dx', 'dt', 'nk', 'hsSM', 'incidenceAngle', 'sigma0', 'normalizedVariance', 'cspcRe', 'cspcIm', 'py_S']\n",
    "\n",
    "def parse_filename(filename):\n",
    "    \"\"\"\n",
    "    Grab some meta data from filename.\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(filename)\n",
    "    #platform, date, _ext = re.split('_|\\.', filename)\n",
    "    platform, _alt, date, _ext = re.split('_|\\.', filename)\n",
    "    assert _alt == 'ALT', _alt\n",
    "    assert _ext == 'nc', _ext\n",
    "    satellite = int(platform[2] == 'A') # Encodes type A as 1 and B as 0\n",
    "    #rval = {'satellite':satellite}\n",
    "    assert date[:5] == 'coloc'\n",
    "    date = date[5:]\n",
    "    year = int(date[0:4])\n",
    "    month = int(date[4:6])\n",
    "    rval = {'satellite':satellite, 'year':year, 'month':month}\n",
    "    return rval\n",
    "\n",
    "def process(x, key):\n",
    "    \"\"\"\n",
    "    Process a netcdf variable data.variables[key]\n",
    "    \"\"\"\n",
    "    if key == 'S':\n",
    "        x.set_auto_scale(False)\n",
    "        x = np.array(x[:] * float(x.scale_factor))\n",
    "    return x\n",
    "\n",
    "def aggregate(files_src, file_dest, keys=None):\n",
    "    \"\"\"\n",
    "    Aggregate list of netcdf files into single hdf5.\n",
    "    Args:\n",
    "    files_src: list of netcdf filenames\n",
    "    file_dest: filename of h5\n",
    "    keys: If specified, only extract these fields.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, filename in enumerate(tqdm(files_src)):\n",
    "        # Add file of data to large hdf5.\n",
    "        #print(filename)\n",
    "        data = Dataset(filename)\n",
    "        meta = parse_filename(filename)\n",
    "        \n",
    "        if i == 0:\n",
    "            if keys is None:\n",
    "                # Grab keys from first file.\n",
    "                keys = data.variables.keys()\n",
    "            with h5py.File(file_dest, 'w') as fdest:\n",
    "                for key in keys:\n",
    "                    #print(key)\n",
    "                    x = process(data.variables[key], key)\n",
    "                    maxshape = (None,) if len(x.shape)==1 else (None, ) + x.shape[1:]\n",
    "                    fdest.create_dataset(key, data=x, maxshape=maxshape)\n",
    "                for key in meta:\n",
    "                    temp = np.ones((data.variables[keys[0]].shape[0], ), dtype=int) * meta[key] \n",
    "                    fdest.create_dataset(key, data=temp, maxshape = (None,))\n",
    "        else:\n",
    "            with h5py.File(file_dest, 'a') as fdest:\n",
    "                for key in keys:\n",
    "                    num_prev = fdest[key].shape[0]\n",
    "                    num_add = data.variables[key].shape[0]\n",
    "                    fdest[key].resize(num_prev + num_add, axis = 0)\n",
    "                    fdest[key][-num_add:] = process(data.variables[key], key)\n",
    "                for key in meta:\n",
    "                    num_prev = fdest[key].shape[0]\n",
    "                    fdest[key].resize(num_prev + num_add, axis = 0)\n",
    "                    fdest[key][-num_add:] = np.ones((data.variables[keys[0]].shape[0], ), dtype=int) * meta[key] \n",
    "\n",
    "aggregate(files_src, file_dest, keys=keys)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/lts/nfs_fs02/sadow_lab/preserve/stopa/sar_hs/data/S1_tropicalCyclones/S1A_tropCylV01S.nc', '/mnt/lts/nfs_fs02/sadow_lab/preserve/stopa/sar_hs/data/S1_tropicalCyclones/S1B_tropCylV01S.nc']\n"
     ]
    }
   ],
   "source": [
    "print(files_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'satellite': 0, 'year': 2019, 'month': 1}\n",
      "dict_keys(['timeSAR', 'lonSAR', 'latSAR', 'hsSM', 'incidenceAngle', 'trackAngle', 'sigma0', 'normalizedVariance', 'S', 'fileNameL1', 'fileNameL2', 'cspcRe', 'cspcIm', 'k', 'th'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(62015, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/mnt/lts/nfs_fs02/sadow_lab/preserve/stopa/sar_hs/competition/S1_2019/S1B_201902S.nc'\n",
    "filename = '/mnt/lts/nfs_fs02/sadow_lab/preserve/stopa/sar_hs/competition/S1_2019/S1B_201901S.nc'\n",
    "meta = parse_filename(filename)  \n",
    "data = Dataset(filename)\n",
    "print(meta)\n",
    "keys = data.variables.keys()\n",
    "print(keys)\n",
    "data.variables['S'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
